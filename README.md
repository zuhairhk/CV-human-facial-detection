# üß† Facial Emotion Detection (Hybrid CV + ML)

## Overview
This project detects **human emotions** from facial expressions using a **hybrid Computer Vision + Machine Learning** approach.  
We use **OpenCV** and **dlib** for facial feature detection, and extracted geometric features are later classified using traditional ML models.

---

## ‚öôÔ∏è Setup Instructions

### 1Ô∏è‚É£ Clone the repository
```bash
git clone https://github.com/<your-username>/cv843-emotion-detection.git
cd cv843-emotion-detection
```

### 2Ô∏è‚É£ Create a virtual environment
```bash
python3 -m venv .venv
```

### 3Ô∏è‚É£ Activate the virtual environment
- **Linux / macOS**
  ```bash
  source .venv/bin/activate
  ```
- **Windows (PowerShell)**
  ```bash
  .venv\Scripts\activate
  ```

You should now see `(.venv)` appear before your terminal prompt.

---

### 4Ô∏è‚É£ Install dependencies
```bash
pip install opencv-python dlib numpy imutils scikit-learn matplotlib
```

> üß© If `dlib` fails to install, make sure you have build tools:
> ```bash
> sudo apt install cmake g++ python3-dev
> ```

---

### 5Ô∏è‚É£ Download required model file
Download the pre-trained facial landmark model:

üì¶ **[shape_predictor_68_face_landmarks.dat](https://github.com/davisking/dlib-models/raw/master/shape_predictor_68_face_landmarks.dat.bz2)**  
Then extract it:
```bash
bunzip2 shape_predictor_68_face_landmarks.dat.bz2
```
and place it in the **root** of this project directory.

---

## ‚ñ∂Ô∏è Running the Code

### Detect facial landmarks in an image:
```bash
python detect_landmarks.py --image path/to/image.jpg
```

### (Optional) Real-time webcam test:
```bash
python detect_landmarks_live.py
```

---

## üîÅ Reactivating the Environment (Every Time You Work)

Each time you reopen the project:
```bash
cd ~/Documents/Code/CV-human-facial-detection
source .venv/bin/activate
```

When you‚Äôre done:
```bash
deactivate
```

---
